# -*- coding: utf-8 -8_

from __future__ import print_function
from __future__ import unicode_literals

import sys
import re
import pymorphy2

from settings import Settings

reload(sys)
sys.setdefaultencoding('utf-8')

class TextProcessor(object):
    """
    ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ°.

    """

    def __init__(self, language):

        self.language = language
        self.settings = Settings()

        # Ğ·Ğ½Ğ°ĞºĞ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ±ÑƒĞ´ÑƒÑ‚ ÑƒĞ´Ğ°Ğ»ÑÑ‚ÑŒÑÑ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ Ğ¸ ĞºĞ¾Ğ½Ñ†Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ°
        self.punctuation = "âˆ™!â€¼Â¡\"#Â£â‚¬$Â¥%&'()*+Â±Ã—Ã·Â·,-./:;<=>?Â¿@[\]^Ë†Â¨_`â€”â€“Â­{|}~â‰ˆâ‰ â†’â†“Â¬â€™â€œâ€Â«" \
                           "Â»â‰«â€˜â€¦Â¦â€ºğŸŒ¼â€²â€³Â¹Â§Â¼â…œÂ½Â¾â…˜Â©âœ’â€¢â–ºâ—â˜…â¤â¡âœâšâ˜â”âœ”â“â’â‘âââââŒâ‹âŠâ¸â·â– â€ âœâœŒï¿¼ï¸Â³â€Â²â€šâ€ â€‹"

        # Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ¸ Ğ½Ğ° Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ°Ğ¼ Ğ¸ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ğ¼ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼
        self.splitchars = re.compile(r'[\s\\\/\(\)\[\]\<\>\;\:\,\â€š\â€”\?\!\|\"â€¦#=]|\.\.\.+|\-\-|\.[\'\"â€™â€œâ€â€˜â€²â€³â€-]')

        if self.language == 'ru':
            # self.stopwords = resource_loader.load_stop_words_ru()
            self.stopwords = self.settings.stop_words_ru
            self.lemmatizer_ru = pymorphy2.MorphAnalyzer()

    @staticmethod
    def normalize_e(word):

        """ ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ñ€ÑƒÑÑĞºÑƒÑ 'Ñ‘' --> 'Ğµ' """

        if 'Ñ‘' in word:
            word = word.replace('Ñ‘', 'Ğµ')

        return word

    def process_line(self, line):
        """
        ĞœĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ñ‚ĞµĞºÑÑ‚Ğ°,
        Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµÑ‚ ĞµÑ‘ Ğ½Ğ° ÑĞ»Ğ¾Ğ²Ğ° Ğ¿Ğ¾ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ğ¾Ğ¼Ñƒ Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ,
        ÑĞ»Ğ¾Ğ²Ğ° Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚.
        Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
        """

        if self.language == 'ru':
            tokens = (self.normalize_e(token.strip(self.punctuation).lower()) for token in self.splitchars.split(line))

            rslt_list = (self.lemmatizer_ru.parse(term)[0].normal_form for term in tokens if term in self.stopwords and len(term) > 0)

        return rslt_list

    def process_text(self, text):
        """
        ĞŸÑ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´ Ñ†ĞµĞ»Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚,
        Ğ¾Ñ‚Ğ´Ğ°ĞµÑ‚ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾Ñ‡Ğ½Ğ¾ Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ process_line
        """

        terms_list = []

        for term in self.process_line(text):
            terms_list.append(term)

        return terms_list

    def iterate_over_texts(self, texts_set):
        """
        ĞœĞµÑ‚Ğ¾Ğ´ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ñ‚ĞµĞºÑÑ‚Ğ°Ğ¼ 
        Ğ¸ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ process_text.
        Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼
        ĞºĞ»ÑÑ‡ - ÑÑ‚Ğ¾ Ñ‚ĞµĞºÑÑ‚,
        Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ - ÑĞ¿Ğ¸ÑĞ¾Ğº ĞµĞ³Ğ¾ Ğ»ĞµĞ¼Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
        """

        texts_stemmed = {}

        for text in texts_set:

            text_stemmed = self.process_text(text)

            if len(text_stemmed) > 0:

                texts_stemmed[text] = text_stemmed

        return texts_stemmed
